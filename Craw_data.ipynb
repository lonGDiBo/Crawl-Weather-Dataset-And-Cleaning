{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Craw Data<center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.request # download the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bgc-jena.mpg.de/wetter/weather_data.html'\n",
    "page = requests.get(url)\n",
    "if page.status_code == 200: # 200 means OK\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "else:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td align=\"center\" valign=\"top\" width=\"33%\">\n",
       "<a href=\"mpi_roof.zip\">ZIP-file 01.07.2023 up to today</a><br>\n",
       "<a href=\"mpi_roof_2023a.zip\">ZIP-file 01.01.2023 to 30.06.2023</a><br>\n",
       "<a href=\"mpi_roof_2022b.zip\">ZIP-file 01.07.2022 to 31.12.2022</a><br>\n",
       "<a href=\"mpi_roof_2022a.zip\">ZIP-file 01.01.2022 to 30.06.2022</a><br>\n",
       "<a href=\"mpi_roof_2021b.zip\">ZIP-file 01.07.2021 to 31.12.2021</a><br/>\n",
       "<a href=\"mpi_roof_2021a.zip\">ZIP-file 01.01.2021 to 30.06.2021</a><br/>\n",
       "<a href=\"mpi_roof_2020b.zip\">ZIP-file 01.07.2020 to 31.12.2020</a><br/>\n",
       "<a href=\"mpi_roof_2020a.zip\">ZIP-file 01.01.2020 to 30.06.2020</a><br/>\n",
       "<a href=\"mpi_roof_2019b.zip\">ZIP-file 01.07.2019 to 31.12.2019</a><br/>\n",
       "<a href=\"mpi_roof_2019a.zip\">ZIP-file 01.01.2019 to 30.06.2019</a><br/>\n",
       "<a href=\"mpi_roof_2018b.zip\">ZIP-file 01.07.2018 to 31.12.2018</a><br/>\n",
       "<a href=\"mpi_roof_2018a.zip\">ZIP-file 01.01.2018 to 30.06.2018</a><br/>\n",
       "<a href=\"mpi_roof_2017b.zip\">ZIP-file 01.07.2017 to 31.12.2017</a><br/>\n",
       "<a href=\"mpi_roof_2017a.zip\">ZIP-file 01.01.2017 to 30.06.2017</a><br/>\n",
       "<a href=\"mpi_roof_2016b.zip\">ZIP-file 01.07.2016 to 31.12.2016</a><br/>\n",
       "<a href=\"mpi_roof_2016a.zip\">ZIP-file 01.01.2016 to 30.06.2016</a><br/>\n",
       "<a href=\"mpi_roof_2015b.zip\">ZIP-file 01.07.2015 to 31.12.2015</a><br/>\n",
       "<a href=\"mpi_roof_2015a.zip\">ZIP-file 01.01.2015 to 30.06.2015</a><br/>\n",
       "<a href=\"mpi_roof_2014b.zip\">ZIP-file 01.07.2014 to 31.12.2014</a><br/>\n",
       "<a href=\"mpi_roof_2014a.zip\">ZIP-file 01.01.2014 to 30.06.2014</a><br/>\n",
       "<a href=\"mpi_roof_2013b.zip\">ZIP-file 01.07.2013 to 31.12.2013</a><br/>\n",
       "<a href=\"mpi_roof_2013a.zip\">ZIP-file 01.01.2013 to 30.06.2013</a><br/>\n",
       "<a href=\"mpi_roof_2012b.zip\">ZIP-file 01.07.2012 to 31.12.2012</a><br/>\n",
       "<a href=\"mpi_roof_2012a.zip\">ZIP-file 01.01.2012 to 30.06.2012</a><br/>\n",
       "<a href=\"mpi_roof_2011b.zip\">ZIP-file 01.07.2011 to 31.12.2011</a><br/>\n",
       "<a href=\"mpi_roof_2011a.zip\">ZIP-file 01.01.2011 to 30.06.2011</a><br/>\n",
       "<a href=\"mpi_roof_2010b.zip\">ZIP-file 01.07.2010 to 31.12.2010</a><br/>\n",
       "<a href=\"mpi_roof_2010a.zip\">ZIP-file 01.01.2010 to 30.06.2010</a><br/>\n",
       "<a href=\"mpi_roof_2009b.zip\">ZIP-file 01.07.2009 to 31.12.2009</a><br/>\n",
       "<a href=\"mpi_roof_2009a.zip\">ZIP-file 01.01.2009 to 30.06.2009</a><br/>\n",
       "<a href=\"mpi_roof_2008b.zip\">ZIP-file 01.07.2008 to 31.12.2008</a><br/>\n",
       "<a href=\"mpi_roof_2008a.zip\">ZIP-file 01.01.2008 to 30.06.2008</a><br/>\n",
       "<a href=\"mpi_roof_2007b.zip\">ZIP-file 01.07.2007 to 31.12.2007</a><br/>\n",
       "<a href=\"mpi_roof_2007a.zip\">ZIP-file 01.01.2007 to 30.06.2007</a><br/>\n",
       "<a href=\"mpi_roof_2006b.zip\">ZIP-file 01.07.2006 to 31.12.2006</a><br/>\n",
       "<a href=\"mpi_roof_2006a.zip\">ZIP-file 01.01.2006 to 30.06.2006</a><br/>\n",
       "<a href=\"mpi_roof_2005b.zip\">ZIP-file 01.07.2005 to 31.12.2005</a><br/>\n",
       "<a href=\"mpi_roof_2005a.zip\">ZIP-file 01.01.2005 to 30.06.2005</a><br/>\n",
       "<a href=\"mpi_roof_2004b.zip\">ZIP-file 01.07.2004 to 31.12.2004</a><br/>\n",
       "<a href=\"mpi_roof_2004a.zip\">ZIP-file 01.01.2004 to 30.06.2004</a><br/>\n",
       "<a href=\"mpi_roof_2003b.zip\">ZIP-file 24.11.2003 to 31.12.2003</a><br/>\n",
       "</br></br></br></br></td>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = soup.find('td',align='center', valign=\"top\" ) # find the table\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download succesful mpi_roof.zip\n",
      "Download succesful mpi_roof_2023a.zip\n",
      "Download succesful mpi_roof_2022b.zip\n",
      "Download succesful mpi_roof_2022a.zip\n",
      "Download succesful mpi_roof_2021b.zip\n",
      "Download succesful mpi_roof_2021a.zip\n",
      "Download succesful mpi_roof_2020b.zip\n",
      "Download succesful mpi_roof_2020a.zip\n",
      "Download succesful mpi_roof_2019b.zip\n",
      "Download succesful mpi_roof_2019a.zip\n",
      "Download succesful mpi_roof_2018b.zip\n",
      "Download succesful mpi_roof_2018a.zip\n",
      "Download succesful mpi_roof_2017b.zip\n",
      "Download succesful mpi_roof_2017a.zip\n",
      "Download succesful mpi_roof_2016b.zip\n",
      "Download succesful mpi_roof_2016a.zip\n",
      "Download succesful mpi_roof_2015b.zip\n",
      "Download succesful mpi_roof_2015a.zip\n",
      "Download succesful mpi_roof_2014b.zip\n",
      "Download succesful mpi_roof_2014a.zip\n",
      "Download succesful mpi_roof_2013b.zip\n",
      "Download succesful mpi_roof_2013a.zip\n",
      "Download succesful mpi_roof_2012b.zip\n",
      "Download succesful mpi_roof_2012a.zip\n",
      "Download succesful mpi_roof_2011b.zip\n",
      "Download succesful mpi_roof_2011a.zip\n",
      "Download succesful mpi_roof_2010b.zip\n",
      "Download succesful mpi_roof_2010a.zip\n",
      "Download succesful mpi_roof_2009b.zip\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Studying\\Tiểu luận chuyên ngành\\data_WH\\Crawl-Weather-Dataset-And-Cleaning\\Craw_data.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Studying/Ti%E1%BB%83u%20lu%E1%BA%ADn%20chuy%C3%AAn%20ng%C3%A0nh/data_WH/Crawl-Weather-Dataset-And-Cleaning/Craw_data.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Down file zip\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Studying/Ti%E1%BB%83u%20lu%E1%BA%ADn%20chuy%C3%AAn%20ng%C3%A0nh/data_WH/Crawl-Weather-Dataset-And-Cleaning/Craw_data.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Studying/Ti%E1%BB%83u%20lu%E1%BA%ADn%20chuy%C3%AAn%20ng%C3%A0nh/data_WH/Crawl-Weather-Dataset-And-Cleaning/Craw_data.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlretrieve(zip_url, zip_filename) \u001b[39m# download file\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Studying/Ti%E1%BB%83u%20lu%E1%BA%ADn%20chuy%C3%AAn%20ng%C3%A0nh/data_WH/Crawl-Weather-Dataset-And-Cleaning/Craw_data.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownload succesful \u001b[39m\u001b[39m{\u001b[39;00mzip_filename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Studying/Ti%E1%BB%83u%20lu%E1%BA%ADn%20chuy%C3%AAn%20ng%C3%A0nh/data_WH/Crawl-Weather-Dataset-And-Cleaning/Craw_data.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m reporthook:\n\u001b[0;32m    266\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m--> 268\u001b[0m \u001b[39mwhile\u001b[39;00m block \u001b[39m:=\u001b[39m fp\u001b[39m.\u001b[39;49mread(bs):\n\u001b[0;32m    269\u001b[0m     read \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(block)\n\u001b[0;32m    270\u001b[0m     tfp\u001b[39m.\u001b[39mwrite(block)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:472\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[0;32m    470\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    471\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[1;32m--> 472\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[0;32m    473\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[0;32m    474\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    475\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    708\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1249\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1245\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1246\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1247\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1248\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1249\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1250\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1104\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1105\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1106\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1107\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for link in files.find_all('a'):\n",
    "    zip_url = 'https://www.bgc-jena.mpg.de/wetter/' + link.get('href')\n",
    "    zip_filename = zip_url.split(\"/\")[-1]\n",
    "    # Down file zip\n",
    "    try:\n",
    "        urllib.request.urlretrieve(zip_url, zip_filename) # download file\n",
    "        print(f\"Download succesful {zip_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error {zip_url}: {str(e)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Afterward, move all files with the \".zip\" extension to a different folder for convenience in processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Extract zip file<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write function extract zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def extract_all_zips(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder {folder_path} Error.\")\n",
    "        return\n",
    "    \n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        if os.path.isfile(file_path) and file.lower().endswith(\".zip\"):\n",
    "            try:\n",
    "                with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(folder_path)\n",
    "                print(f\"Extract succesfull {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Extract error {file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_10888\\3456661151.py:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  folder_path = \"E:\\Studying\\Tiểu luận chuyên ngành\\data_WH\\Crawl-Weather-Dataset-And-Cleaning\\Data_craw\" # path to folder contain zip files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract succesfull mpi_roof_2010a.zip\n",
      "Extract succesfull mpi_roof_2010b.zip\n",
      "Extract succesfull mpi_roof_2011a.zip\n",
      "Extract succesfull mpi_roof_2011b.zip\n",
      "Extract succesfull mpi_roof_2012a.zip\n",
      "Extract succesfull mpi_roof_2012b.zip\n",
      "Extract succesfull mpi_roof_2013a.zip\n",
      "Extract succesfull mpi_roof_2013b.zip\n",
      "Extract succesfull mpi_roof_2014a.zip\n",
      "Extract succesfull mpi_roof_2014b.zip\n",
      "Extract succesfull mpi_roof_2015a.zip\n",
      "Extract succesfull mpi_roof_2015b.zip\n",
      "Extract succesfull mpi_roof_2016a.zip\n",
      "Extract succesfull mpi_roof_2016b.zip\n",
      "Extract succesfull mpi_roof_2017a.zip\n",
      "Extract succesfull mpi_roof_2017b.zip\n",
      "Extract succesfull mpi_roof_2018a.zip\n",
      "Extract succesfull mpi_roof_2018b.zip\n",
      "Extract succesfull mpi_roof_2019a.zip\n",
      "Extract succesfull mpi_roof_2019b.zip\n",
      "Extract succesfull mpi_roof_2020a.zip\n",
      "Extract succesfull mpi_roof_2020b.zip\n",
      "Extract succesfull mpi_roof_2021a.zip\n",
      "Extract succesfull mpi_roof_2021b.zip\n",
      "Extract succesfull mpi_roof_2022a.zip\n",
      "Extract succesfull mpi_roof_2022b.zip\n",
      "Extract succesfull mpi_roof_2023a.zip\n",
      "Extract succesfull mpi_roof_2023b.zip\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"E:\\Studying\\Tiểu luận chuyên ngành\\data_WH\\Crawl-Weather-Dataset-And-Cleaning\\Data_craw\" # path to folder contain zip files\n",
    "extract_all_zips(folder_path)  # extract all zip files in folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Merger file csv <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Đường dẫn đến các file CSV cần gộp\n",
    "file_paths = glob.glob('E:/Studying/Tiểu luận chuyên ngành/data_WH/Crawl-Weather-Dataset-And-Cleaning/Data_craw/*.csv')\n",
    "\n",
    "# Tạo một DataFrame trống để lưu dữ liệu gộp\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Đọc và gộp các file CSV vào DataFrame\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path, encoding='latin1')\n",
    "    combined_data = pd.concat([combined_data, df])\n",
    "\n",
    "# Lưu dữ liệu gộp vào file CSV\n",
    "combined_data.to_csv('E:/Studying/Tiểu luận chuyên ngành/data_WH/Crawl-Weather-Dataset-And-Cleaningcombined_file.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
